<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">

	<title>Talk | ML Conference Berlin, 2018 | Machine Learning in the Browser</title>

	<meta name="description" content="Machine learning in a web browser?! Yes, you read that correctly! Machine learning is typically regarded as the purview of traditional scientific computing environments such as Python and MATLAB. However, recent advances in web technologies are rapidly opening a new frontier for machine learning which extends beyond the desktop and into your browser. In this session, I'll discuss the current state-of-the-art for machine learning in the browser and introduce libraries for high-performance linear algebra, statistical computing, and neural networks. I'll highlight how changes in web standards are facilitating the rise of these libraries and thus accelerating the adoption of browser-based machine learning. I'll follow with lessons learned while implementing machine learning algorithms for use in web applications, discussing common implementation mistakes, portability issues, and how to maximize performance. And finally, I'll conclude by offering insight into how you can take advantage of the next big machine learning revolution, all within your browser!">
	<meta name="author" content="Athan Reines">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<!-- Icons -->
	<link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
	<link rel="manifest" href="manifest.json">
	<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
	<meta name="theme-color" content="#ffffff">

	<!-- Facebook Open Graph -->
	<meta property="og:type" content="website">
	<meta property="og:site_name" content="stdlib">
	<meta property="og:url" content="https://stdlib.io/">
	<meta property="og:title" content="A standard library for JavaScript and Node.js.">
	<meta property="og:description" content="stdlib is a standard library for JavaScript and Node.js, with an emphasis on numeric computing.">
	<meta property="og:locale" content="en_US">
	<meta property="og:image" content="">

	<!-- Twitter -->
	<meta name="twitter:card" content="A standard library for JavaScript and Node.js.">
	<meta name="twitter:site" content="@stdlibjs">
	<meta name="twitter:url" content="https://stdlib.io/">
	<meta name="twitter:title" content="stdlib">
	<meta name="twitter:description" content="stdlib is a standard library for JavaScript and Node.js, with an emphasis on numeric computing.">
	<meta name="twitter:image" content="">

	<!-- Stylesheets -->
	<link rel="stylesheet" href="css/grid.css">
	<link rel="stylesheet" href="css/font-awesome.css">
	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/white.css">
	<link rel="stylesheet" href="css/style.css">

	<!-- Code syntax highlighting -->
	<link rel="stylesheet" href="css/code/zenburn.css">

	<!-- Equation rendering -->
	<link rel="stylesheet" href="js/lib/katex/katex.css">
	<script defer src="js/lib/katex/katex.min.js"></script>
	<script defer src="js/lib/katex/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

	<!-- Printing and PDF exports -->
	<script src="js/lib/reveal/pdf.js"></script>

	<!--[if lt IE 9]>
	<script src="js/lib/reveal/html5shiv.js"></script>
	<![endif]-->
</head>

<body>

	<header>
		<a href="https://github.com/stdlib-js/stdlib"><img src="img/long_logo_white.svg" alt="stdlib"></a>
	</header>

	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides">
			<section id="mlconf-splash" class="center" data-transition="fade-out" data-background-image="img/mlcon_2018_template_2048x1536_47881_v1a.png">

				<aside class="notes">

				</aside>
			</section>

			<section id="title-slide" class="center">
				<h1>Machine Learning in the Browser</h1>

				<aside class="notes">

				</aside>
			</section>

			<section id="pre-splash" class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section id="splash" class="center" data-transition="fade-out">
				<div>
					<a href="https://github.com/stdlib-js/stdlib"><img src="img/long_logo_white.svg" alt="stdlib" class="undecorated" height="35%" width="35%"></a>
				</div>
				<div>
					<small><a href="https://github.com/kgryte"><i class="fa fa-github"></i> Athan Reines</a> | <a href="https://twitter.com/kgryte"><i class="fa fa-twitter"></i> @kgryte</a> | <a href="https://twitter.com/stdlibjs"><i class="fa fa-twitter"></i> @stdlibjs</a></small>
				</div>
				<aside class="notes">
					<p>
						My name is Athan Reines, and I work full-time on the open-source project, stdlib, a standard library for JavaScript and Node.js, with an emphasis on <strong>numerical</strong> and <strong>scientific</strong> computing applications, including machine learning.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Overview</h2>

				<div class="row">
					<ul class="column column-3">
						&nbsp;
					</ul>
					<ol class="column column-8">
						<li class="fragment">Motivation</li>
						<li class="fragment">JavaScript</li>
						<li class="fragment">Examples</li>
						<li class="fragment">Libraries and Frameworks</li>
						<li class="fragment">Web Standards</li>
						<li class="fragment">Tips and Tricks</li>
						<li class="fragment">Conclusions</li>
					</ol>
				</div>

				<aside class="notes">
					<p>
						The talk overview is as follows...
					</p>
					<ul>
   						<li>
   							First, I will motivate why machine learning in browser environments is important and why you should care.
   						</li>
   						<li>
   							Next, as this talk concerns machine learning in the browser, I will discuss JavaScript as it relates to machine learning.
   						</li>
   						<li>
   							Then, I will walk through some browser-based machine learning examples.
   						</li>
   						<li>
   							I'll then highlight a few promising libraries and frameworks for browser-based machine learning.
   						</li>
   						<li>
   							Next, I'll discuss what is happening at the standards level which is making the web platform a better environment for machine learning.
   						</li>
   						<li>
   							Then, I'll offer some tips and tricks.
   						</li>
   						<li>
   							And finally, I will offer some conclusions and additional resources you can use to get up and running.
   						</li>
   					</ul>
					<p>
						If I move too quickly, this talk is on-line, <strong>with notes</strong>, so you can revisit during and after this conference.
					</p>
					<p>
						Simply go to my GitHub page, or follow me on Twitter where I'll tweet a link to the talk slides.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Why machine learning in the browser?</h2>

				<ul>
					<li class="fragment">Privacy</li>
					<li class="fragment">Low latency</li>
					<li class="fragment">Offline</li>
					<li class="fragment">Power efficient</li>
					<li class="fragment">Direct access to sensor data</li>
				</ul>

				<aside class="notes">
					<p>
						Why is machine learning in the browser exciting?
					</p>
					<p>
						Running machine learning algorithms in the browser allows for localized model <strong>training</strong> and <strong>prediction</strong>/<strong>classification</strong>. I don't need to decouple these two aspects: training and prediction.
					</p>
					<p>
						Meaning, in practice, for particular types of problems, I do not need dedicated infrastructure or processes/threads for training and separate infrastructure for prediction.
					</p>
					<p>
						Not only does this stand in contrast to traditional "big data" architectures, but this also stands in notable contrast to environments such as Jupyter notebooks, which effectively make the browser a glorified RPC client and require a backend server architecture to actually receive and execute commands.
					</p>
					<p>
						Why is this distinction important? For the following reasons...
					</p>
					<p>
						Privacy. Running machine learning algorithms in browser environments allows data to stay on-device. For example, health and fitness trackers, such as the Apple Watch, now have APIs which allow you to access heart beat data. By running incremental machine learning algorithms on-device, I can train a model (i.e., learn a user's "normal" heart beat pattern) and then detect when a heart beat, or set of heart beats, no longer fits this pattern. In this scenario, I never have to send this data to remote servers.
					</p>
					<p>
						Because I don't have to send data to remote servers, analysis has low latency, works offline, and can be more power efficient.
					</p>
					<p>
						Finally, as analysis can occur on-device (or using newer buzzword terminology, at the "edge"), we can have direct access to device sensor data, which removes the need for often complex device data serialization and de-serialization logic.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					To help motivate machine learning use cases, let us consider some real-world datasets...
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Example Datasets</h2>

				<ul>
					<li class="fragment">Mouse/cursor movements</li>
					<li class="fragment">Scrolling</li>
					<li class="fragment">Clicks</li>
					<li class="fragment">Sensors</li>
					<li class="fragment">Monitoring</li>
				</ul>

				<aside class="notes">
					<p>
						In browser environments, we have data streams such as mouse and cursor movements, scrolling, and "clicks".
					</p>
					<p>
						With modern web APIs, we have access to sensor data, such as device orientation, temperature, and ambient lighting; all data which is being continuously recorded.
					</p>
					<p>
						And finally, we have monitoring data, such as logs of failed HTTP/S requests, application errors, et cetera.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Use Cases</h2>

				<ul>
					<li class="fragment">Forecasting</li>
					<li class="fragment">Anomalies</li>
					<li class="fragment">Clustering</li>
				</ul>

				<aside class="notes">
					<p>
						What can machine learning in browser environments allow you to do?
					</p>
					<p>
						The short answer is most everything you can do in non-browser environments. The main exception being the batch analysis of data of sufficient scale to be impractical for a single device.
					</p>
					<p>
						As particularly concerns browser environments...
					</p>
					<p>
						For the UI interaction data we discussed in the previous slide, such as cursor movement and scrolling, we can generate a prediction as to what resource a user will most likely need next, allowing us to create what would feel like a faster and more responsive UI.
					</p>
					<p>
						One example I have seen in a real-world application is tracking cursor movement and, based on (x,y) coordinates over time, training a model to predict which button a user will click next, causing the desired resource to be fetched before a user actually clicks the button, and thereby leading to a more instantaneous experience.
					</p>
					<p>
						Another classic use case is anomaly detection, such as detecting a malfunctioning system or fraudulent activity. In this classification task, we want to detect when a datum, or set of datums, is different than the rest.
					</p>
					<p>
						The sooner we are able to classify new data as "anomalous", the sooner we can fix a potential problem.
					</p>
					<p>
						A third use case is clustering, which is the process of assigning groups.
					</p>
					<p>
						As an example, we could collect device performance metrics and identify different application "states", such as resource intensive, idle, et cetera.
					</p>
					<p>
						The number of states and how frequently they are occupied could be informative for on-device resource planning and optimization.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Why JavaScript?</h2>

				<aside class="notes">
					<p>
						At this point, we should ask: okay, well, machine learning is useful, but why do any of this in JavaScript? Don't other languages exist which are better suited to the task? And don't the advantages of those other languages outweigh any potential benefits of running machine learning algorithms in browser environments?
					</p>
					<p>
						As a practitioner who has written and used machine learning algorithms in other languages, I can confidently say that JavaScript is as equally qualified as any of those other languages, such as R and Python, for machine learning tasks.
					</p>
					<p>
						However, the stigma that JavaScript is <strong>not</strong> suitable for math (and, by association, machine learning) persists, so I would like to take a moment to dispel a couple of myths...
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Myths</h2>

				<ul>
					<li class="fragment">Performance</li>
					<li class="fragment">Incompatibility</li>
				</ul>

				<aside class="notes">
					<p>
						The first myth is poor performance. As part of our work on stdlib, we have written and run the benchmarks. You can run them yourself. They are publicly available.
					</p>
					<p>
						JavaScript environments are just as fast as, and more often than not, faster than, Python and easily faster than R.
					</p>
					<p>
						Modern JavaScript environments are highly optimized and continually improving. With WebAssembly and Node.js native add-ons, reaching near-native speed in JavaScript environments is readily achievable.
					</p>
					<p>
						The second myth is that JavaScript is somehow incompatible with mathematical computation.
					</p>
					<p>
						The argument in support of this myth typically goes something like single-threaded, something, something, floating-point, something, something, 64-bit integers.
					</p>
					<p>
						What is clear about the people making this argument is that they have not used other languages for scientific computing and machine learning, because many of the arguments used against JavaScript apply equally to other languages used for mathematical computation.
					</p>
					<p>
						People can, and, more importantly, <strong>do</strong> write robust and performant mathematical code in JavaScript.
					</p>
					<p>
						Personally, I can point to stdlib and the fact that we've implemented literally thousands of mathematical functions in JavaScript and have not encountered any overwhelming issues due to the language itself.
					</p>
					<p>
						This said, yes, some languages have syntactical features more amenable to terser code (e.g., operator overloading), but the lack of these features does not preclude math algorithms from being implemented.
					</p>
					<p>
						In fact, e.g., C suffers from similar operator overloading limitations and no one who believes the "JavaScript cannot do math" myth seems to believe the same about C.
					</p>
					<p>
						In short, many of those who say math cannot be done in JavaScript seem to have various preconceptions which are not grounded in reality and most likely have never written mathematical libraries.
					</p>
					<p>
						The <strong>primary</strong> reason why people do not currently do mathematical computation in JavaScript (and, by association, browser environments) is that other ecosystems already have a critical mass of libraries and frameworks for doing mathematical computation.
					</p>
					<p>
						The issue is not one of technical limitations, but one of community support--a problem that myself and colleagues are working to address with stdlib.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Examples</h2>

				<aside class="notes">
					<p>
						To help dispel the aforementioned myths, let's now turn to some examples demonstrating machine learning in JavaScript, and not just any machine learning, but <strong>real-time machine learning</strong>.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Anomaly Detection</h2>

				<aside class="notes">
					<p>
						The first example is real-time anomaly detection.
					</p>
					<p>
						To help structure the example, I've prepared an interactive Observable notebook which steps through an analysis of network sensor data.
					</p>
					<p>
						For the purposes of this talk, the sensor data is static; however, all the analytical components shown in the notebook are amenable to real-time analysis, with each analytical component being an incremental accumulator which accepts data as it arrives.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Clustering</h2>

				<aside class="notes">
					<p>
						The second example is real-time clustering.
					</p>
					<p>
						Similar to the previous example, I've prepared an interactive Observable notebook which steps through an analysis of simulated data.
					</p>
					<p>
						For the purposes of this talk, I chose to use simulated data as we have control over the data's generation and are able to know the true underlying state of the simulated system.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Regression</h2>

				<aside class="notes">
					<p>
						The third example is real-time regression.
					</p>
					<p>
						As with the previous two examples, I've prepared an interactive Observable notebook.
					</p>
					<p>
						For this notebook, we analyze Boston house prices.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Classification</h2>

				<aside class="notes">
					<p>
						The fourth example is real-time classification. See stdlib.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Libraries and Frameworks</h2>

				<aside class="notes">
					<p>
						At this point, I want to highlight various libraries and frameworks for browser-based machine learning.
					</p>
					<p>
						We have already seen one such library: stdlib, a project of which I am part. But there are others worth noting.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform"><a href="https://beta.observablehq.com">Observable</a></h2>

				<ul class="fragment">
					<li><a href="https://beta.observablehq.com/@rreusser/domain-coloring-for-complex-functions">Domain Coloring</a></li>
					<li><a href="https://beta.observablehq.com/@gcalmettes/routes-to-chaos">Routes to Chaos</a></li>
					<li><a href="https://beta.observablehq.com/@patternleaf/federal-budget-in-a-bottle">Federal Budget</a></li>
				</ul>

				<aside class="notes">
					<p>
						The first is Observable, a reactive notebook environment which exclusively leverages the web platform.
					</p>
					<p>
						Similar to Jupyter notebooks, one can use Observable to create interactive notebooks which interleave prose and code, aiding exploration and analysis.
					</p>
					<p>
						To showcase a few examples...
					</p>
					<p>
						The first of which is a <a href="https://beta.observablehq.com/@rreusser/domain-coloring-for-complex-functions">notebook</a> which explores techniques for visualizing complex functions.
					</p>
					<p>
						In this notebook, the author mixes prose and code to demonstrate visualization techniques. What makes Observable particularly compelling is that one is able to freely use all the technologies associated with the web platform. In this case, the author showcases how to use WebGL to generate stunning visualization of complex functions with interactive elements.
					</p>
					<p>
						The next <a href="https://beta.observablehq.com/@gcalmettes/routes-to-chaos">notebook</a> explores chaotic systems.
					</p>
					<p>
						In this notebook, the author is exploring how to reason about and model chaotic systems. Again, similar to other notebooks, we see the mixing of prose and code, coupled with interactivity, allowing the reader to better understand what is chaos and how can we reason about it.
					</p>
					<p>
						The last <a href="https://beta.observablehq.com/@patternleaf/federal-budget-in-a-bottle">notebook</a> allows you to better reason about the US Federal Budget, by mapping budget expenditures to equivalent amounts in your monthly budget.
					</p>
					<p>
						For those familiar with the work of Brett Victor, we can see that Observable provides an environment and framework for creating explorable explanations.
					</p>
					<p>
						In fact, this is one of the advantages of Observable when compared to other notebook environments, such as Jupyter. Observable, being a "reactive" environment, supporting an out-of-order execution model, lends itself to a tighter integration between analysis and exploration and creative coding.
					</p>
					<p>
						This tighter integration allows developers and analysts alike to more powerfully and expressively probe and interact with both their data and the algorithms which operate on that data (as we saw in the real-time machine learning notebooks we saw earlier).
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform"><a href="https://js.tensorflow.org/">Tensorflow.js</a></h2>

				<ul class="fragment">
					<li><a href="https://beta.observablehq.com/@nkreeger/visualizing-ml-training-using-tensorflow-js-and-baseball-d">Predicting Strikes</a></li>
				</ul>

				<aside class="notes">
					<p>
						Another library is tensorflow.js, a machine learning library being actively developed by a team within Google Brain.
					</p>
					<p>
						Tensorflow.js aims to bring the power of Tensorflow to JavaScript environments, allowing you to train and deploy machine learning models in web browsers and Node.js.
					</p>
					<p>
						(...explore tensorflow examples--posenet and pacman--on the tensorflow.js website...)
					</p>
					<p>
						A last tensorflow.js example is an Observable <a href="https://beta.observablehq.com/@nkreeger/visualizing-ml-training-using-tensorflow-js-and-baseball-d">notebook</a> for training a model on MLB strike data and then using the trained model to predict strikes.
					</p>
					<p>
						(...watch the live demo...)
					</p>
					<p>
						What is important to note about this notebook is (1) all model training and evaluation happens entirely on the client. No servers needed.
					</p>
					<p>
						And (2) neural networks are often treated as a black box, things which are hard to understand and reason about. By moving machine learning from traditional environments, such as R and Python, to the browser, we are able to tighten the feedback loop to visualize how an algorithm, even a neural network black box, learns in real-time, allowing us to explore and probe how, in a sense, an algorithm "thinks".
					</p>
					<p>
						And thus, we should not underestimate the importance of browser-based machine learning as an important pedagogical device.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Apache Arrow</h2>

				<ul class="fragment">
					<li><a href="https://beta.observablehq.com/@theneuralbit/using-apache-arrow-js-with-large-datasets">Large Datasets</a></li>
				</ul>

				<aside class="notes">
					<p>
						The last library I want to highlight is Apache Arrow.
					</p>
					<p>
						Apache Arrow specifies a <strong>standardized language-independent</strong> columnar memory format for flat and hierarchical data, organized for efficient analytic operations on modern hardware.
					</p>
					<p>
						One of the main goals of Apache Arrow is to provide a common data format which can be used across environments and language, thus avoiding data serialization and deserialization costs.
					</p>
					<p>
						To demonstrate using Apache Arrow in browser environments, we can open another Observable <a href="https://beta.observablehq.com/@theneuralbit/using-apache-arrow-js-with-large-datasets">notebook</a> which showcases how to use Apache Arrow with large datasets.
					</p>
					<p>
						In this notebook, we can readily load and manipulate a few hundred thousand records--in this case, Chicago crime statistics--all within the browser environment.
					</p>
					<p>
						For those who are unimpressed and consider a few hundred thousand records to be "tiny", keep in mind two things: (1) when performing exploratory data analysis on large datasets, doing so on an entire dataset is impractical; rather, one commonly performs exploratory data analysis on a "representative" sample.
					</p>
					<p>
						(2) in theory, while a browser does have memory limitations, it does also have access to close to half a user's hard drive. By appropriately leveraging in-browser databases and stream APIs, one can, under certain circumstances, readily analyze many gigabytes of data, entirely within a browser environment.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Web Standards</h2>

				<aside class="notes">
					<p>
						Now that we have discussed libraries and frameworks for browser-based machine learning, I want to highlight recent developments at the standards level which is helping accelerate the development and evolution of machine learning on the web.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">WebAssembly</h2>

				<aside class="notes">
					<p>
						One of the most well-publicized developments is WebAssembly.
					</p>
					<p>
						Building of the collective efforts of the past 20 years, browser vendors came together to achieve consensus on binary format for the web.
					</p>
				</aside>
			</section>

			<section class="center">
				<p>
					A portable compilation target for the web
				</p>

				<aside class="notes">
					<p>
						In short, WebAssembly is a portable compilation target for the web.
					</p>
				</aside>
			</section>

			<section class="center">
				<p>
					Allows running languages other than JavaScript within browser environments
				</p>

				<aside class="notes">
					<p>
						And it allows running languages other than JavaScript within browser environments.
					</p>
					<p>
						More specifically, the current focus is the ability to run statically compiled languages, such as C, C++, and Rust, within browser environments.
					</p>
				</aside>
			</section>

			<section class="center">
				<p>C/C++&nbsp;&nbsp;&nbsp;→&nbsp;&nbsp;&nbsp;IR&nbsp;&nbsp;&nbsp;→&nbsp;&nbsp;&nbsp;wasm&nbsp;&nbsp;&nbsp;→&nbsp;&nbsp;&nbsp;x86/ARM</p>

				<aside class="notes">
					<p>
						Modern compilers are comprised of two components: a frontend compiler, which takes a higher level language like C and compiles it to an intermediate representation, and a backend compiler which takes an intermediate representation and compiles it to machine-specific instructions.
					</p>
					<p>
						Accordingly, in a modern compiler pipeline, WebAssembly (abbreviated: wasm) resides after the intermediate representation.
					</p>
					<p>
						In the shown pipeline, I begin with input source files. A frontend compiler compiles those source files to an intermediate representation.
					</p>
					<p>
						A backend compiler takes the intermediate representation and compiles to WebAssembly.
					</p>
					<p>
						The WebAssembly is subsequently passed to a JavaScript engine, either loaded over HTTP in a browser or read from the filesystem in Node.js.
					</p>
					<p>
						The JavaScript engine then translates the WebAssembly to machine code specific to a host platform.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Two Formats</h2>

				<aside class="notes">
					<p>
						WebAssembly has two formats: a binary encoding and a text format.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Text Format</h2>

				<aside class="notes">
					<p>
						Let's begin with the text format.
					</p>
					<p>
						WebAssembly defines a standardized text format that encodes a WebAssembly module with all its contained definitions in a way that is equivalent to the binary format.
					</p>
					<p>
						As an example...
					</p>
				</aside>
			</section>

			<section class="center">
				<pre><code class="hljs lisp" contenteditable>
(module
  (type $0 (func (param i32 i32) (result i32)))
  (export "add" $add)
  (func $add (type $0) (param $var$0 i32) (param $var$1 i32) (result i32)
    (i32.add
      (get_local $var$0)
      (get_local $var$1)
    )
  )
)
				</code></pre>

				<aside class="notes">
					<p>
						...here is a WebAssembly module which exports a single function "add" which adds two 32-bit integers and returns a 32-bit integer result.
					</p>
					<p>
						Similar to LISP, the text format, commonly referred to as WAT, uses s-expressions for representing the program "tree".
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Value Types</h2>

				<div class="fragment row">
					<ul class="column column-2">&nbsp;</ul>
					<ul class="column column-5">
						<li>i32</li>
						<li>f32</li>
						<li>i64</li>
						<li>f64</li>
					</ul>
				</div>

				<aside class="notes">
					<p>
						Currently, WebAssembly only supports 4 value types, which are all numeric types: 32-bit integers, 32-bit single-precision floating-point numbers, 64-bit integers, and 64-bit double-precision floating-point numbers.
					</p>
					<p>
						Any other value type must be constructed by manipulating raw memory. In practice, this means copying data to the module heap and using pointers.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Binary Encoding</h2>

				<aside class="notes">
					<p>
						Now that we have a simple working example, let's discuss the binary format.
					</p>
					<p>
						The binary format is a dense representation of a WebAssembly module.
					</p>
					<p>
						As an example...
					</p>
				</aside>
			</section>

			<section class="center">
				<pre><code class="hljs text" contenteditable>
00 61 73 6d 01 00 00 00  04 74 79 70 65 87 80 80  |.asm.....type...|
80 00 01 40 02 01 01 01  01 08 66 75 6e 63 74 69  |...@......functi|
6f 6e 82 80 80 80 00 01  00 06 6d 65 6d 6f 72 79  |on........memory|
85 80 80 80 00 80 02 80  02 01 06 65 78 70 6f 72  |...........expor|
74 86 80 80 80 00 01 00  03 61 64 64 04 63 6f 64  |t........add.cod|
65 8c 80 80 80 00 01 86  80 80 80 00 00 14 00 14  |e...............|
01 40 04 6e 61 6d 65 86  80 80 80 00 01 03 61 64  |.@.name.......ad|
64 00                                             |d.|
				</code></pre>

				<aside class="notes">
					<p>
						...here is the same WebAssembly module we saw in text format represented in binary format.
					</p>
					<p>
						If we convert the Hex to a string (right side), we can see that the module is comprised of 6 sections.
					</p>
					<ul>
						<li>preamble</li>
						<li>type</li>
						<li>function</li>
						<li>memory</li>
						<li>export</li>
						<li>code</li>
						<li>name</li>
					</ul>
					<p>
						Each section begins with the name of the section, followed by the total number of bytes comprising that section.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Memory Access</h2>

				<div class="row">
					<ul class="column column-5">
						<li>i32.load8_s (signed)</li>
						<li>i32.load8_u (unsigned)</li>
						<li>i32.load16_s</li>
						<li>i32.load16_u</li>
						<li>i32.load</li>
						<li>i64.load8_s</li>
						<li>i64.load8_u</li>
						<li>i64.load16_s</li>
						<li>i64.load16_u</li>
						<li>i64.load32_s</li>
						<li>i64.load32_u</li>
					</ul>
					<ul class="column column-3">
						<li>i64.load</li>
						<li>f32.load</li>
						<li>f64.load</li>
						<li>i32.store8</li>
						<li>i32.store16</li>
						<li>i32.store</li>
						<li>i64.store8</li>
						<li>i64.store16</li>
						<li>i64.store32</li>
						<li>i64.store</li>
						<li>f32.store</li>
					</ul>
					<ul class="column column-3">
						<li>f64.store</li>
					</ul>
				</div>

				<aside class="notes">
					Linear memory access is accomplished with explicit store and load operators.
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Control Constructs</h2>

				<div class="row">
					<ul class="column column-2">&nbsp;</ul>
					<ul class="column column-5">
						<li>nop</li>
						<li>block</li>
						<li>loop</li>
						<li>if</li>
						<li>else</li>
						<li>br</li>
						<li>br_if</li>
						<li>br_table</li>
						<li>return</li>
						<li>end</li>
					</ul>
				</div>

				<aside class="notes">
					WebAssembly offers basic control flow constructs, such as ifs, loops, and blocks.
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Operators</h2>

				<div class="row">
					<ul class="column column-2">&nbsp;</ul>
					<ul class="column column-5">
						<li>i32.add</li>
						<li>i32.sub</li>
						<li>i32.mul</li>
						<li>i32.div_s</li>
						<li>i32.div_u</li>
						<li>i32.rem_s</li>
						<li>i32.rem_u</li>
						<li>i32.and</li>
						<li>...<a href="http://webassembly.org/docs/semantics/#32-bit-integer-operators">many more</a></li>
					</ul>
				</div>

				<aside class="notes">
					<p>
						The current WebAssembly specification defines many operators and functions for data type conversion, truncation, reinterpretation, promotion, and demotion.
					</p>
					<p>
						Here, I am listing operators for 32-bit integers. For the complete list of operators, see the specification.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Advantages</h2>

				<div class="fragment row">
					<ul class="column column-2">&nbsp;</ul>
					<ul class="column column-5">
						<li>Compact</li>
						<li>Parsing</li>
						<li>Typed</li>
						<li>Optimization</li>
						<li>Deoptimization</li>
						<li>Lower-level</li>
						<li>GC</li>
						<li>Performance</li>
					</ul>
				</div>

				<aside class="notes">
					<p>
						WebAssembly has several stated advantages...
					</p>
					<ul>
						<li>
							First, the binary format is compact, which means fewer bytes must be sent across a network and faster load times.
						</li>
						<li>
							Next, because the binary format is structured, having a defined layout, module loaders need to only perform a single-pass in order to parse an encoded module into an AST in preparation for translating to machine code. The advantage of only requiring a single-pass is that modules can be instantiated faster compared to a module written in vanilla JavaScript.
						</li>
						<li>
							Third, WebAssembly is strongly typed, which means more efficient serialization and, again, fewer bytes sent across a network.
						</li>
						<li>
							<p>
								Next, because WebAssembly is strongly typed, compilers are able to perform ahead-of-time optimizations. This is in contrast to JavaScript, for instance, which first must be compiled and monitored to determine if particular functions are running "hot".
							</p>
							<p>
								Once a function is "hot", the function is sent to an optimizing compiler which makes optimistic assumptions about input value types and code paths, essentially creating an optimized version of the "hot" function.
							</p>
							<p>
								If a function receives an unexpected input value type, the optimized function is de-optimized and the cycle repeats indefinitely or until a function is put in "deoptimization hell".
							</p>
							<p>
								So instead of runtime optimization, with WebAssembly, we can perform the optimization an optimizing compiler does before ever running in a JavaScript runtime.
							</p>
						</li>
						<li>
							Next, because WebAssembly is strongly typed, we are able to avoid de-optimizing cycles as the optimization/deoptimization loop is no longer needed: input and output value types are defined ahead-of-time and not something a runtime compiler must empirically discover.
						</li>
						<li>
							Another advantage is that WebAssembly is lower-level, which means that WebAssembly is easier to translate to efficient and optimized machine instructions, which means faster execution.
						</li>
						<li>
							<p>
								Next, WebAssembly does not currently come with a garbage collector, which means that WebAssembly modules are responsible for manually managing memory. This is useful as this allows control over when memory is allocated and deallocated, as you might want to during "deadtime", i.e., when an application is running idle.
							</p>
							<p>
								On the flip side, the lack of GC also means that languages which depend on a GC cannot be easily compiled to WebAssembly (e.g., Python, et al).
							</p>
						</li>
						<li>
							If we combine all of these advantages, WebAssembly promises, for certain applications, better performance compared to JavaScript.
						</li>
				</aside>
			</section>

			<section class="center">
				<pre><code class="hljs c" contenteditable>
// File: dasum.c
#include &lt;math.h&gt;

double c_dasum( const int N, const double *X, const int stride ) {
    double sum;
    int m;
    int n;
    int i;

    sum = 0.0;
    if ( N &lt;= 0 || stride &lt;= 0 ) {
        return sum;
    }
    // If the stride is equal to `1`, use unrolled loops...
    if ( stride == 1 ) {
        m = N % 6;

        // If we have a remainder, run a clean-up loop...
        if ( m > 0 ) {
            for ( i = 0; i &lt; m; i++ ) {
                sum += fabs( X[i] );
            }
        }
        if ( N &lt; 6 ) {
            return sum;
        }
        for ( i = m; i &lt; N; i += 6 ) {
            sum += fabs( X[i] ) + fabs( X[i+1] ) + fabs( X[i+2] ) + fabs( X[i+3] ) + fabs( X[i+4] ) + fabs( X[i+5] );
        }
        return sum;
    }
    n = N * stride;
    for ( i = 0; i &lt; n; i += stride ) {
        sum += fabs( X[i] );
    }
    return sum;
}
				</code></pre>

				<aside class="notes">
					<p>
						To demonstrate the performance advantages, here is a BLAS function, which computes the sum of absolute values over a strided array.
					</p>
					<p>
						If we compile to WebAssembly and run benchmarks, we get the following results...
					</p>
				</aside>
			</section>

			<section class="center" data-transition="slide-in slide-out" data-transition-speed="default">
				<table>
					<thead>
						<tr>
							<th>Length</th>
							<th>JavaScript</th>
							<th>wasm</th>
							<th>Native</th>
							<th>Perf</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>10</td>
							<td>22,438,020</td>
							<td>18,226,375</td>
							<td>7,084,870</td>
							<td>2.57x</td>
						</tr>
						<tr>
							<td>100</td>
							<td>4,350,384</td>
							<td>6,428,586</td>
							<td>6,428,626</td>
							<td>1.0x</td>
						</tr>
						<tr>
							<td>1,000</td>
							<td>481,417</td>
							<td>997,234</td>
							<td>3,289,090</td>
							<td>0.30x</td>
						</tr>
						<tr>
							<td>10,000</td>
							<td>28,186</td>
							<td>110,540</td>
							<td>355,172</td>
							<td>0.31x</td>
						</tr>
						<tr>
							<td>100,000</td>
							<td>1,617</td>
							<td>11,157</td>
							<td>30,058</td>
							<td>0.37x</td>
						</tr>
						<tr>
							<td>1,000,000</td>
							<td>153</td>
							<td>979</td>
							<td>1,850</td>
							<td>0.53x</td>
						</tr>
					</tbody>
				</table>
				<aside class="notes">
					<p>
						Note that native is hardware optimized BLAS.
					</p>
					<p>
						Note when compared to native add-on implementing reference BLAS that performance is the basically the same (i.e., wasm matches native performance).
					</p>
					<p>
						However, native add-ons have a significant advantage of being able to utilize hardware optimized libraries. Hardware optimized libraries will win every time.
					</p>
					<p>
						For server environments, WebAssembly is <strong>NOT</strong> a replacement for Node.js native add-ons.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Web Standards</h2>

				<ul>
					<li class="fragment">BigInt</li>
					<li class="fragment">Value Types</li>
				</ul>

				<aside class="notes">
					<p>
						A couple other initiatives happening at the standards level are <strong>BigInt</strong>, which brings arbitrary-precision integers (similar to Python) to JavaScript, and <strong>value types</strong>, which could potentially pave a path for custom types (e.g., complex numbers) and operator overloading and thus more terse syntax for expressing mathematical operations over vectors, matrices, and n-dimensional arrays.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Tips and Tricks</h2>

				<ul>
					<li class="fragment">Avoid Built-ins</li>
					<li class="fragment">Read the Source!</li>
					<li class="fragment">Data Structures</li>
					<ul>
						<li class="fragment">ndarray</li>
						<li class="fragment">circular buffers</li>
						<li class="fragment">trees</li>
					</ul>
					<li class="fragment">Algorithms</li>
				</ul>

				<aside class="notes">
					<p>
						So...tips and tricks. The following tips are generally applicable regardless of whether a machine learning algorithm is written and used in JavaScript.
					</p>
					<p>
						The first tip, which is perhaps most applicable to JavaScript, is to avoid built-in mathematical functions (i.e., those mathematical functions which are defined by the ECMAScript standard and part of JavaScript's built-in standard library).
					</p>
					<p>
						For a variety of historical reasons, the built-in implementations are ill-defined (allowing browser vendors to make trade-offs between speed and accuracy) and commonly have bugs.
					</p>
					<p>
						Since one cannot specify the exact environment version in which browser-based machine learning algorithms will run (i.e., your users may have browsers spanning from the ancient to the most recent, with everything in between), if you want to ensure reproducibility of even the most basic mathematical operations, use community libraries, such as stdlib.
					</p>
					<p>
						Second, the ecosystem for browser-based numerical, scientific, and machine learning libraries is in significant flux, with no clear "winner" among many contenders.
					</p>
					<p>
						Accordingly, in order to ensure that you use quality implementations, you currently <strong>cannot</strong> rely on proxies for assessing quality, such as stars and downloads.
					</p>
					<p>
						Especially within the JavaScript community, libraries and frameworks are born and die every day, with significant hype-driven herding propelling library adoption.
					</p>
					<p>
						The most reliable approach for assessing whether to use a library is by <strong>reading. the. source.</strong>
					</p>
					<p>
						Next, while true in general, but especially for machine learning, what makes algorithms performant are two things.
					</p>
					<p>
						The first is using the right data structure.
					</p>
					<p>
						One such data structure is n-dimensional arrays (ndarrays), which are single-segment contiguous blocks of memory. These data structures allow for more efficient cache optimization.
					</p>
					<p>
						Another common data structure for real-time machine learning algorithms is a circular buffer. While the textbook definition is simple, these need to be implemented carefully in order to avoid poor memory management, especially when implementing them in JavaScript.
					</p>
					<p>
						Certain machine learning algorithms, and, in particular, real-time algorithms, require specialized tree data structures. One such algorithm is quantile approximation.
					</p>
					<p>
						The second is using the right algorithm.
					</p>
					<p>
						One example where using the right algorithm is critical is, again, quantile approximation. A naive approach would require storing all data in memory and sorting the data each time a new data arrives.
					</p>
					<p>
						A better approach is use an approximate method which uses a tree data structure and an acceptable error rate.
					</p>
					<p>
						In batch analysis, especially for one-off analyses, we can be okay using naive algorithms or less efficient data structures; however, in the context of real-time statistical analysis and machine learning within web applications, this is not viable.
					</p>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center" data-transition="fade-in fade-out" data-transition-speed="default">
				<h2 class="no-text-transform">Conclusions</h2>

				<div class="row">
					<ul class="column column-3">
						&nbsp;
					</ul>
					<ul class="column column-8">
						<li class="fragment">JavaScript</li>
						<li class="fragment">Data Structures</li>
						<li class="fragment">Algorithms</li>
						<li class="fragment">Get Involved!</li>
					</ul>
				</div>

				<aside class="notes">
					<p>
						There are 4 points I want you to remember from this talk...
					</p>
					<ol>
						<li>
							First, JavaScript is perfectly suitable for mathematical computation and machine learning. And not only is machine learning in JavaScript and browser environments possible, but doing so introduces new types of machine learning applications, which offer better data privacy, better performance, and better resource utilization. In the words of Brendan Eich, "Always bet on JavaScript".
						</li>
						<li>
							Second, machine learning algorithms, especially real-time machine learning algorithms, require using the right data structure, regardless of what language they are implemented in.
						</li>
						<li>
							Third, machine learning algorithms require using the right algorithm.
						</li>
						<li>
							Last, get involved! People are building the future of machine learning on the web, and we need people like you to continue making that future possible. That means contributing to open-source libraries, writing Observable notebooks to showcase new and interesting machine learning applications, and getting your companies to help sponsor, either through developer time or funding, machine learning development for the web.
						</li>
					</ol>
				</aside>
			</section>

			<section class="center">
				<aside class="notes">
					(next slide)
				</aside>
			</section>

			<section class="center" data-transition="fade-in fade-out" data-transition-speed="default">
				<h2 class="no-text-transform">Thank you!</h2>

				<aside class="notes">
					...and with that, thank you!
				</aside>
			</section>

			<section class="center">
				<div>
					<a href="https://github.com/stdlib-js/stdlib"><img src="img/hex_sticker_black.svg" alt="stdlib" class="undecorated"></a>
				</div>

				<p>
					<small><a href="https://github.com/stdlib-js/stdlib"><i class="fa fa-github"></i> https://github.com/stdlib-js/stdlib</a></small>
					<br>
					<small><a href="https://www.patreon.com/athan"><i class="fa fa-bitcoin"></i> https://www.patreon.com/athan</a></small>
				</p>

				<aside class="notes">
					<p>
						If you want to find more machine learning examples, be sure to see stdlib, a standard library for Node.js and JavaScript, with an emphasis on scientific computing, where we have additional resources and many examples.
					</p>
					<p>
						If you want stickers, come find me!
					</p>
				</aside>
			</section>

			<section>
				<!-- Add blank slide to separate main presentation from appendix -->
				<aside class="notes">
					Intentionally left blank.
				</aside>
			</section>

			<section class="center">
				<h2>Appendix</h2>
			</section>

			<section class="center">
				<!-- Intentionally many lines -->
				<pre><code class="hljs javascript" contenteditable>




















				</code></pre>
				<aside class="notes">
					Slide for code editing.
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Machine Learning</h2>

				<aside class="notes">
					<p>
						Machine learning is applied mathematics and statistics and largely resides in the domain of computer science.
					</p>
					<p>
						In contrast to the field of statistics, where we focus on mathematical formulas, the derivation of robust estimators, and developing mathematical techniques for modeling problem domains...
					</p>
					<p>
						...in computer science, we focus less on mathematical purity and more on the practical aspects of writing algorithms which can run efficiently and with high performance and give us results which are not perfect, but "good enough".
					</p>
					<p>
						The primary aim of machine learning is to find patterns in data, to find the proverbial signal in the noise, via numerical computation.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Models</h2>

				<p class="fragment">
					$$y = a_nx_n + a_{n-1}x_{n-1} + \cdots + a_0x_0 + b$$
				</p>

				<aside class="notes">
					<p>
						To describe those patterns we want to find, we <em>formulate</em> and <em>train</em> <strong>models</strong>.
					</p>
					<p>
						A model is a mathematical formulation summarizing the nature of, and describing the relationship between, data variables.
					</p>
					<p>
						Models serve as the statistical foundation for machine learning.
					</p>
					<p>
						In order for machine learning algorithms to find patterns in data, we must "train" (or "teach") machine learning algorithms as to what those patterns are.
					</p>
					<p>
						In a sense, machine learning algorithms "learn" the models used to describe particular patterns. That learning often comes in the form of learning specific values of coefficients within an equation.
					</p>
					<p>
						In this equation, those coefficients would be a_n, a_{n-1}, a_0, et cetera.
					</p>
					<p>
						As a more concrete example...
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">What will be the temperature tomorrow?</h2>

				<div class="row">
					<p class="fragment column column-4" style="padding-top: 0.9em">
						$$t_{n+1} = t_{n}$$
					</p>
					<p class="fragment column column-4">
						$$t_{n+1} = \frac{1}{7} \sum_{i=n-6}^{n} t_i$$
					</p>
					<p class="fragment column column-4">
						$$t_{n+1} = \frac{1}{W} \sum_{i=n-W+1}^{n} t_i$$
					</p>
				</div>

				<aside class="notes">
					<p>
						...suppose we want to "predict" the temperature tomorrow. A naive approach would be to predict that the temperature tomorrow is whatever the temperature is today.
					</p>
					<p>
						Our naive approach can be expressed mathematically as t_{n+1} = t_{n}, which is a way of saying that, for a given day n+1, the temperature should equal the temperature of the previous day. This equation is our model.
					</p>
					<p>
						However, we might, perhaps rightly, believe that this naive approach might not be as accurate as we would like due to day-to-day temperature variability (i.e., noise).
					</p>
					<p>
						For example, an anomalous weather pattern may lead to extreme variation, such as a very warm day followed by a very cold day, but, for most climates, such extreme variability would not be "normal".
					</p>
					<p>
						So, one possible refinement would be to predict that the temperature tomorrow is the average temperature of the past, say, 7 days.
					</p>
					<p>
						By taking the average, we will "smooth" out some of the day-to-day variability and hopefully have a more reliable estimate over the long term.
					</p>
					<p>
						In other words, by using the average temperature of the previous 7 days to predict tomorrow's temperature, our predictions will be closer (i.e., have a smaller <strong>error</strong>), on average, to the actual temperature than had we used our naive model.
					</p>
					<p>
						We can generalize our model by using the parameter W which represents the number of days we want to average over.
					</p>
					<p>
						In this example, the "model" is the mathematical formula describing the computation of the average temperature. That model is "trained" by giving the model data (e.g., the temperature for each of the past 7 days). In this case, the output of the trained model is a single value, which we then use to "predict" tomorrow's temperature.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Training Algorithms</h2>

				<div class="row">
					<ul class="column column-12">
						<li class="fragment"><strong>Batch</strong>: build a model from a "batch" of data</li>
						<li class="fragment"><strong>Incremental</strong>: continuously update a model as data arrives</li>
						<li class="fragment"><strong>Mini-batch</strong>: hybrid of batch and incremental training.</li>
					</ul>
				</div>

				<aside class="notes">
					<p>
						How we train machine learning algorithms comes in three varieties.
					</p>
					<p>
						The first is "batch". Batch training means training a model over an entire dataset. In order to accommodate new data, we must re-train our model by performing batch training over the entire updated data set.
					</p>
					<p>
						Many "big data"/map-reduce style algorithms (e.g., such as those run on Hadoop) are of this variety.
					</p>
					<p>
						The second is "incremental". Incremental training means training a model incrementally, one datum at a time. Such an approach allows one to continuously update a model as data arrives, without having to re-train over the entire data set.
					</p>
					<p>
						The third is mini-batch, which is a hybrid of batch and incremental. In this variety, we buffer data and train models in small batches.
					</p>
					<p>
						The primary motivation for mini-batch is the ability to achieve some of the robustness of batch training with a reasonably close approximation of the immediacy of incremental training (i.e., mini-batch can achieve "near real-time").
					</p>
				</aside>
			</section>

			<section class="center">
				<h2 class="no-text-transform">Real-Time Machine Learning</h2>

				<aside class="notes">
					<p>
						I define real-time machine learning as the subset of machine learning algorithms which support incremental training. I.e., as a new datum arrives, I can update my model incrementally. Meaning, in order to generate a new prediction, I don't need to <strong>store</strong> and analyze <strong>all</strong> past prior events.
					</p>
					<p>
						Commonly, perhaps due to marketing departments, you'll see machine learning approaches and technologies labeled as "real-time". These approaches are more accurately described as "near real-time", in which, due to distributed computing strategies and/or parallelization, they allow for re-training and analysis to be done more quickly than traditional batch analysis.
					</p>
					<p>
						My definition excludes these near real-time approaches.
					</p>
					<p>
						Why this limited definition? Because I find incremental machine learning algorithms particularly compelling, especially when used in browser environments.
					</p>
				</aside>
			</section>

			<section class="center">
				<h2>The End</h2>
			</section>

		</div>

	</div>

	<footer>
		<a href="https://github.com/kgryte"><i class="fa fa-github"></i> Athan Reines</a> | <a href="https://twitter.com/kgryte"><i class="fa fa-twitter"></i> @kgryte</a> | <a href="https://twitter.com/stdlibjs"><i class="fa fa-twitter"></i> @stdlibjs</a>
	</footer>

	<script src="js/lib/reveal/head.min.js"></script>
	<script src="js/lib/reveal/reveal.js"></script>
	<script src="js/lib/reveal/init.js"></script>
	<script src="js/script.js"></script>
</body>
</html>
